\startfirstchapter{Introduction} \label{ch:1}
\section{Background and Motivation}
An interface is what forms a common boundary between two phases of matter. The phases of matter can be of any form, i.e, solid, liquid, and gas. The behavior of a surface greatly affects the properties of a material, such as oxidation, corrosion, chemical activity, deformation and fracture, surface energy and tension, adhesion, bonding, friction, lubrication, wear and contamination. Therefore, surface characterization identification remains an active area of research in the physics, chemistry, and biotechnology communities as well as in modern electronic technology. It also plays a crucial role in surface science. Among various surface properties, molecular orientation is a key factor of all, because molecular orientation greatly affects molecules' surface properties in aspects such as: adhesion, lubrication, catalysis, bio-membrane functions and so on. \cite{PhysRevB.59.12632}\\

Many experimental techniques have been applied in the study of molecular orientation at interfaces. Among them the optical methods are more preferable. Such methods include infrared (IR) absorption, Raman scattering and visible-infrared sum-frequency generation (SFG) spectroscopy. All these vibrational spectra carry quantitative structural information of molecules at interfaces. Although each of them has its own strengths and shortcomings, they all share the following advantages when compared with other non-optical methods. First of all, they all can be applied to any interfaces accessible by light. Second, they are non-destructive. Third, they are highly sensitive to good spatial, temporal and spectral resolutions \cite{Brasselet:11},\cite{PhysRevB.59.12632}. An important advantage of SFG techniques is: it can discriminate against bulk contributions. This means that its result will not take the effect from the bulk (TODO: double check with Dennis). In order to extract the quantitative structural information that molecules carry at interfaces, different spectroscopy techniques and analyse are required. Combining different spectroscopy techniques is a very effective way to achieve the goal of molecular study. However, finding the most effective ways to combine these techniques may not be clear sometimes.\\

In order to analyse these vibrational spectra, various factors need to be considered. For example, a molecule's vibrational mode in the molecular frame, the orientation average of the molecules adsorbed onto the interface based on the mathematical distribution function(TODO: further explained) and projecting the vibrational mode properties from molecular frame to laboratory frame. The main focus of our study is to analyze the data of these three spectroscopy techniques using Linear Programming (LP). In the following, we will explore how LP can facilitate extracting quantitative structural information of molecules at interfaces.\\

Our approach is to first study a model of a small molecule using LP. We then apply our finding and method to real molecules which are six amino acids: methionine, leucine, isoleucine, alanine, threonine and valine.\\

Before we explain the LP technique and LP model, as well as describe the molecules studied, we introduce the basic theory of  the IR, Raman and SFG spectra.\\

\section{Experimental Probes: IR, Raman, SFG}
Vibrational spectra (IR, Raman and SFG) are produced by the changes of a molecule's dipole moment and polarizability. The dipole moment and polarizability are changing as the molecule's conformation is changing. \\

For IR, its absorption is the absorption-transmission-reflection mode (resonant). The physical principle is the variation of the static dipole moment $\mu$ (the first rank tensor) along the normal coordinates $Q$: $\sfrac{\partial\mu}{\partial Q}$. 

\begin{equation} \label{eq:1.1}
I_{IR} \approx \left| \frac{1}{\sqrt{2m_{Q}w_{Q}}} \frac{\partial\mu}{\partial Q} \right|^{2}
\end{equation}
where $m_{Q}$ is the reduced mass of the normal mode, and $w_{Q}$ is the resonance frequency. The dipole moment $\mu$ is a vector of $x$, $y$ and $z$. The dipole moment derivatives can be expressed as Equation \ref{eq:1.2}. The IR spectra can be obtained from 3 polarizations: $x$, $y$, $z$. 

\begin{equation} \label{eq:1.2}
\frac{\partial\mu}{\partial Q} = \begin{bmatrix}
									\sfrac{\partial\mu_{x}}{\partial Q} \\
									\sfrac{\partial\mu_{y}}{\partial Q} \\
									\sfrac{\partial\mu_{z}}{\partial Q}
								  \end{bmatrix}
\end{equation}

Raman is scattered from the molecule sample. Unlike IR, Raman spectra relate to the variation of the molecular polarizability $\alpha$ (the second rank tensor) along the normal coordinates $Q$: $\sfrac{\partial\alpha}{\partial Q}$. 

\begin{equation} \label{eq:1.3}
I_{Raman} \approx \left| \frac{1}{\sqrt{2m_{Q}w_{Q}}} \frac{\partial\alpha^{(1)}}{\partial Q} \right|^{2}
\end{equation}

where $|0\rangle$, $\langle 1|$, $m$ are same as defined above. $w$ is the resonance frequency. The polarizability is coupled with $(x, y, z)$ components of the driving field and $x, y, z$ components of the induced dipole. Therefore, there are 9 elements in the polarizability, which can be expressed as Equation \ref{eq:1.4}. Furthermore, it results in 9 polarizations of Raman spectra: $xx$, $yy$, $zz$, $xy$, $xz$, $yx$, $yz$, $zy$ and $zx$. \\

\begin{equation} \label{eq:1.4}
\frac{\partial\alpha^{(1)}}{\partial Q} = \begin{bmatrix}
\dfrac{\partial\alpha_{xx}^{(1)}}{\partial Q} & \dfrac{\partial\alpha_{xy}^{(1)}}{\partial Q} & \dfrac{\partial\alpha_{xz}^{(1)}}{\partial Q} \\
\dfrac{\partial\mu_{yx}}{\partial Q} & \dfrac{\partial\alpha_{yy}^{(1)}}{\partial Q} & \dfrac{\partial\alpha_{yz}^{(1)}}{\partial Q}\\
\dfrac{\partial\mu_{zx}}{\partial Q} & \dfrac{\partial\alpha_{zy}^{(1)}}{\partial Q} & \dfrac{\partial\alpha_{zz}^{(1)}}{\partial Q}
\end{bmatrix}
\end{equation}

SFG stands for sum frequency generation vibrational spectroscopy. It is a surface-specific technique. SFG is a non-linear optical process. It is sensitive to the molecular orientation in odd orders. Comparing to linear optical spectroscopy, the biggest advantage of SFG is that it is surface specific. The spectroscopy signal only comes from the surface, not the bulk. SFG is the variation of the outer product of dipole moment and polarizability, $\chi^{(2)}$ (the third rank tensor): $\sfrac{\partial\mu}{\partial Q} \otimes \sfrac{\partial\alpha}{\partial Q} $. Therefore, there are 27 elements for SFG spectra, which result in 27 polarizations of SFG spectra. \\

\begin{equation} \label{eq:1.5}
I_{SFG} \approx \left| \frac{1}{2m_{Q}w_{Q}} \left( \frac{\partial\alpha^{(1)}}{\partial Q} \otimes \frac{\partial\mu}{\partial Q} \right) \right|^{2}
\end{equation}

\section{Linear programming}
Linear Programming (LP) problems are an optimization problems of a specific form. The standard form of LP is a minimization problem that has an objective function and constraints as shown in Equation \ref{eq:1.6} \cite{UULP}:

\begin{eqnarray}  \label{eq:1.6}
 \text{minimize} & c_{1}x_{1} + c_{2}x_{2} + ... + c_{n} x_{n}  \nonumber \\
 \text{subject to} & a_{11} x_{1} + a_{12} x_{2}+ ... + a_{1n} x_{n} = & b_{1} \nonumber \\
& a_{21} x_{1} + a_{22} x_{2} + ... + a_{2n} x_{n} = & b_{2} \nonumber \\
&\cdot                                    &\cdot \nonumber \\
&\cdot                                    &\cdot \nonumber \\
&\cdot                                    &\cdot \nonumber \\
& a_{m1} x_{1} + a_{m2} x_{2} + ... + a_{mn} x_{n} = & b_{m} \nonumber \\
& x_{1} \geq 0, x_{2} \geq 0, ... ,x_{n} \geq 0, 
\end{eqnarray} 
where $x_{i}$ are the decision variables, $a_{ij}$ is a matrix of know coefficients,  $b_{i}$ and $c_{i}$ are vectors of known coefficients. The expression to be minimized is called objective function. The equalities and the inequalities are constraints are the conditions that the decision variables need to subject to. They specify a convex polytope over which the objective function is to be optimized. \\
%The goal is to minimize the objective function, with $x_{1,...,n}$ as the decision variables. The constraints are the conditions that the decision variables need to subject to. 

The diet problem is a popular example to illustrate the concept of LP. It can be described as follows: a restaurant would like to achieve the minimal nutrition requirement with the lowest price of the food selection as shown in Table \ref{tab:1.1}. For each meal, the minimum requirements for vitamin A, vitamin C and dietary fiber are $0.5~mg$, $15~mg$ and $4~g$. The restaurant has three options: raw carrot, raw white cabbage and pickled cucumber. The table also displays the nutrition contains and the price of each ingredient. With all this information, we need to know how much carrot, cabbage and cucumber to add to each meal, so that the minimal nutrition requirements can be met with the lowest price. In summary, the goal is to minimize the price, and the constraints are the nutrition requirements. Therefore, we come up with a model as shown Equations \ref{eq:1.7} to \ref{eq:1.13}.

\begin{table} \label{tab:1.1}
\begin{center}
\begin{tabular}{| l | l  l  l | l |}
\hline
Food & Carrot & Cabbage & Cucumber & Required per dish \\ \hline
Vitamin A [mg/kg] & 35 & 0.5 & 0.5 & 0.5mg \\ 
Vitamin C [mg/kg] & 60 & 300 & 10 & 15mg \\ 
Dietary Fiber [g/kg] & 30 & 20 & 10 & 4g \\ \hline
price[$\$$/kg] & 0.75 & 0.5 & 0.15 & - \\ \hline
\end{tabular} 
\end{center}
\caption{Sample Input of the Diet Problem}
\end{table}	

\begin{eqnarray} 
\text{minimize} & 0.75x_{1} + 0.5x_{2} +  0.15x_{3}  \label{eq:1.7} \\
\text{subject to} & 35x_{1} + 0.5x_{2} + 0.5x_{3} \geq 0.5 \label{eq:1.8} \\
& 60x_{1} + 300x_{2} + 10x_{3} \geq 15 \label{eq:1.9} \\
& 30x_{1} + 20x_{2} + 10x_{3} \geq 4 \label{eq:1.10} \\
& x_{1} \geq 0  \label{eq:1.11} \\
& x_{2} \geq 0  \label{eq:1.12} \\
& x_{3} \geq 0  \label{eq:1.13}
\end{eqnarray} 
In this LP model, $x_{1}$, $x_{2}$ and $x_{3}$ are decision variables, each presents the amount of the ingredients. Equation \ref{eq:1.7} is the objective function to be minimized. Equation \ref{eq:1.8} to Equation \ref{eq:1.10} describe the nutrition requirements. Equation \ref{eq:1.11} to Equation \ref{eq:1.13} ensure the amount of each ingredient to be greater than 0. With the existing LP solvers that implemented Simplex Method, the optimal solution can be obtained within a second. \\

For a LP problem, there exist only three kinds of solutions: feasible and bounded solutions, feasible and unbounded solutions, and infeasible solutions. If the solution space is feasible and bounded, then there is one optimal solution. If it is feasible but unbounded, then there is a solution space with an infinite number of optimal solutions \cite{LP}. \\

A general LP problem can be a minimization or a maximization problem. Its constraints can be equalities or inequalities. For each non-standard LP problem, there are ways to convert it into its standard form. Furthermore, for a LP problem that contains $n$ decision variables, its solution would be in $n$-dimensional space that is called $R^{n}$, each constraint is a hyperplane that divides this $R^{n}$ space into two half-spaces. Therefore, all the constraints together cut this $R^{n}$ space into a convex polyhedron if there are feasible solutions. This makes LP a convex problem. The benefit of a convex problem is that the local optimal solution is also the global optimum. LP solvers return is the optimal solution. If a LP problem has a unique optimal solution, then this solution is a vertex of the convex polyhedron.\\

LP is a convex, a deterministic process. It is guaranteed to converge to a single global optimum if there is a solution space. LP problems are intrinsically easier to solve than many non-linear problems. \\

Another advantage of LP is that it can deal with thousands of variables, which makes it suitable for the study of a molecule's coordination composition at interfaces. \\

Various algorithms are available in solving LP problems, such as: Simplex algorithm, Interior point, and Path-following algorithms. Both Interior Point and Simplex are common and mature algorithms that work well in practice. Simplex is comparatively easier to understand and implement than Interior Point. Simplex method takes the advantage of the geometric concept that it visits the vertices of the feasible set (convex polyhedron), and check the optimal solution among each visited vertex. The converging approach is also different for these two methods. If there are $n$ decision variables, usually Simplex will converge in $O(n)$ operations with $O(n)$ pivots. Interior point traverses the edges between vertices on a polyhedral set. Generally speaking, Interior point method is faster for larger problems with sparse matrix. However, when experimenting with these two methods, the speed of them is not much different from each other for the current study. For our study, Simplex method has proved to be efficient and effective, it will be used for all the experiments. \\

Last but not the least advantage of LP is its speed. For any LP problem, if it has an optimal solution, this solution is always a vertex. Simplex method is based on this insight, namely that it starts at a vertex, then pivot from vertex to vertex, until it reaches the optimum. Although it has been shown that Simplex method is not a polynomial algorithm, in practice it usually takes $2n-3n$ steps to solve a problem ($n$ is the number of decision variables). \\

The LP solver we use is called ``GNU linear programming tool kit"(GLPK). It has implemented both Simplex and Interior Point methods in ACNSI C. It is open-source and intended to solve large scale LP problems. \\


(TODO: compare linear programming with other tools, like quadratic programming and linear regression)
Compare linear programming with quadratic programming, why linear programming is a better approach to the problem? (Having problems finding related work or how to prove it myself)
	
Is there only computational gain?
Also consider the model itself and solution space	
(The problem is defined as "Candidate ratio problem" in Kai's thesis, same here???)
to determine the level of similarity between spectra is not an easy task 
	
\section{Aims and scope}
Given some target experimental spectra and a set of candidates spectra, to find out the right combination of candidates for the target spectra is the goal in this study. The approach is to build our LP model, and check if the optimal solutions returned by the solver match the target composition that was used to generate the target spectra. The LP models are built using spectra resulting from different techniques. Therefore, there are different LP models. for each of these models, we then analyze which model is best to reach the goal with the highest accuracy. From this, we can decide which spectroscopy technique(s) is sufficiently sensitive in finding the right combination of candidates. Furthermore, we will consider various study focuses, and for each focus, what spectroscopy techniques combined with LP modelling should be applied in order to obtain the accurate composition of the target spectra. 